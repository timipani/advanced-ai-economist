{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2021, salesforce.com, inc.  \n",
    "All rights reserved.  \n",
    "SPDX-License-Identifier: BSD-3-Clause  \n",
    "For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will be used to gather real-world data and perform data processing in order to use it in the covid-19 simulation.\n",
    "\n",
    "### All the downloaded data will be formatted into pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the list of COVID-19 data sources used in this notebook\n",
    "\n",
    "1. **US state government policies** (Oxford Covid-19 Government Response Tracker (OxCGRT))\n",
    "\n",
    "    https://github.com/OxCGRT/USA-covid-policy\n",
    "\n",
    "\n",
    "2. **US federal government direct payments** (Committee for a Responsible Federal Budget)\n",
    "\n",
    "    https://www.covidmoneytracker.org/\n",
    "    \n",
    "    https://docs.google.com/spreadsheets/d/1Nr_J5wLfUT4IzqSXkYbdOXrRgEkBxhX0/edit#gid=682404301\n",
    "    \n",
    "\n",
    "3. **US deaths data** (COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University)\n",
    "\n",
    "    https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "\n",
    "4. **US vaccinations** (Our World in Data)\n",
    "    \n",
    "    https://ourworldindata.org/covid-vaccinations\n",
    "    \n",
    "    \n",
    "5. **US unemployment** (Bureau of Labor and Statistics)\n",
    "\n",
    "    https://www.bls.gov/lau/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.signal import convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes to fetch the real-world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_economist.datasets.covid19_datasets.us_policies import DatasetCovidPoliciesUS\n",
    "from ai_economist.datasets.covid19_datasets.us_deaths import DatasetCovidDeathsUS\n",
    "from ai_economist.datasets.covid19_datasets.us_vaccinations import DatasetCovidVaccinationsUS\n",
    "from ai_economist.datasets.covid19_datasets.us_unemployment import DatasetCovidUnemploymentUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a base directory where you would like to download real world data. The latest data will be downloaded into a folder within the base directory, named using the current date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR_PATH = \"/tmp/covid19_data\"  # SPECIFY A BASE DIRECTORY TO STORE ALL THE DOWNLOADED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_LATEST_DATA = True  # Download the latest data or use whatever is saved earlier \n",
    "CURRENT_DATE = datetime.now()\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "date_string = CURRENT_DATE.strftime(DATE_FORMAT).replace('/','-')\n",
    "data_dir = os.path.join(BASE_DATA_DIR_PATH, date_string)\n",
    "\n",
    "print(\"All the data will be downloaded to the directory: '{}'.\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dictionary to write model constants\n",
    "model_constants = {}\n",
    "model_constants_filename = \"model_constants.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather real-world data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. COVID-19 US State Government Policies\n",
    "### Source: Oxford Covid-19 Government Response Tracker (OxCGRT) \n",
    "(https://github.com/OxCGRT/USA-covid-policy)\n",
    "\n",
    "**NOTE:** All data will use the same format as **policy_df** (below) and use the same date index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_policies_us = DatasetCovidPoliciesUS(\n",
    "    data_dir=data_dir,\n",
    "    download_latest_data=DOWNLOAD_LATEST_DATA\n",
    ")\n",
    "\n",
    "# Which of the policy indicators to treat as the open/close level\n",
    "STRINGENCY_POLICY_KEY = 'StringencyIndex'\n",
    "# Number of levels to discretize the stringency policy into. \n",
    "# In the context of reinforcement learning, this also determines the action space of the agents.\n",
    "NUM_STRINGENCY_LEVELS = 10\n",
    "\n",
    "policies_us_df = covid_policies_us.process_policy_data(\n",
    "    stringency_policy_key=STRINGENCY_POLICY_KEY,\n",
    "    num_stringency_levels=NUM_STRINGENCY_LEVELS\n",
    ")\n",
    "\n",
    "print(\"Policy data are available between {} and {}\".format(policies_us_df[\"Date\"].min(), \n",
    "                                                           policies_us_df[\"Date\"].max()))\n",
    "\n",
    "policy_df = policies_us_df.pivot(\n",
    "    index=\"Date\", columns=\"RegionName\", values=STRINGENCY_POLICY_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the common date index that all the dataframes will use\n",
    "COMMON_DATE_INDEX = policy_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list of states (in order) all the dataframes will use\n",
    "US_STATE_ORDER = policy_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the stringency level for a specified US state\n",
    "state = \"California\"\n",
    "policy_df[state].plot(figsize=(15,5), x='Date', title=\"Stringency Level for {}\".format(state), grid=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. COVID-19 Federal government subsidies (direct payments) to the states\n",
    "### Source: Committee For A Responsible Federal Budget\n",
    "https://www.covidmoneytracker.org/\n",
    "\n",
    "### Direct payments provided by the Federal Government so far are recorded in this google spreadsheet\n",
    "https://docs.google.com/spreadsheets/d/1Nr_J5wLfUT4IzqSXkYbdOXrRgEkBxhX0/edit#gid=682404301\n",
    "### Read as (date: direct payment amount)\n",
    "2020-04-15: 274B\n",
    "\n",
    "2020-12-27: 142B\n",
    "\n",
    "2021-03-11: 386B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsidy_df = pd.DataFrame(policy_df.index).set_index(\"Date\")\n",
    "subsidy_df[\"USA\"] = 0.0\n",
    "\n",
    "subsidy_df.loc[\"2020-04-15\", \"USA\"] = 274e9\n",
    "subsidy_df.loc[\"2020-12-27\", \"USA\"] = 142e9\n",
    "subsidy_df.loc[\"2021-03-11\", \"USA\"] = 386e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. COVID-19 Deaths data\n",
    "### Source: COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University \n",
    "(https://github.com/CSSEGISandData/COVID-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_us_df = DatasetCovidDeathsUS(\n",
    "    data_dir=data_dir,\n",
    "    download_latest_data=DOWNLOAD_LATEST_DATA\n",
    ").df\n",
    "\n",
    "print(\"COVID-19 death data for the US is available between {} and {}\".format(\n",
    "    deaths_us_df.columns[12], deaths_us_df.columns[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain just the states in US_STATE_ORDER\n",
    "deaths_us_df = deaths_us_df[deaths_us_df.Province_State.isin(US_STATE_ORDER)]\n",
    "\n",
    "# We will visualize this later in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. COVID-19 Vaccination Data\n",
    "### Source: Our World in Data\n",
    "(https://ourworldindata.org/covid-vaccinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccinations_us_df = DatasetCovidVaccinationsUS(\n",
    "    data_dir=data_dir,\n",
    "    download_latest_data=DOWNLOAD_LATEST_DATA\n",
    ").df\n",
    "\n",
    "vaccination_dates = sorted(vaccinations_us_df.date.unique())\n",
    "print(\"Vaccination data is available between {} and {}\".format(min(vaccination_dates), max(vaccination_dates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccinated_df = vaccinations_us_df.pivot(\n",
    "    index=\"date\", columns=\"location\", values=\"people_fully_vaccinated\"\n",
    ")[US_STATE_ORDER]\n",
    "\n",
    "vaccinated_df.index = pd.to_datetime(vaccinated_df.index)\n",
    "vaccinated_df = vaccinated_df.reindex(COMMON_DATE_INDEX).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the vaccinations for a specified US state\n",
    "# Warning: the last value may not be updated (may show it to be 0)\n",
    "\n",
    "state = \"California\"\n",
    "vaccinated_df[state].plot(figsize=(15,5), x='Date', title=\"Vaccinations for {}\".format(state), grid=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using deaths and vaccinations to compute the susceptible-infected-recovered (SIR) numbers\n",
    "\n",
    "Our SIR data will only treat **deaths** as ground-truth.\n",
    "\n",
    "Given death data and some assumed constants about the _death rate_ and _recovery rate_ , we can apply some \"SIR algebra\" (i.e. solve for unknowns using the SIR equations) to _infer_ quantities like total \"recovered\", number of infected people, and ultimately **Beta**, which is the rate of transmission times the number of people an infected person comes into contact with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data representation, we will want to build a dataframe for...\n",
    "# ... deaths...\n",
    "deaths_df = pd.DataFrame(COMMON_DATE_INDEX, columns=['Date']).set_index('Date')\n",
    "smoothed_deaths_df = pd.DataFrame(COMMON_DATE_INDEX, columns=['Date']).set_index('Date')\n",
    "# ... (inferred) SIR states...\n",
    "susceptible_df = pd.DataFrame(COMMON_DATE_INDEX, columns=['Date']).set_index('Date')\n",
    "infected_df    = pd.DataFrame(COMMON_DATE_INDEX, columns=['Date']).set_index('Date')\n",
    "recovered_df   = pd.DataFrame(COMMON_DATE_INDEX, columns=['Date']).set_index('Date')\n",
    "# ... and (inferred) Beta.\n",
    "beta_df = pd.DataFrame(COMMON_DATE_INDEX, columns=['Date']).set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD of the Gaussian smoothing window applied to the death data.\n",
    "SIR_SMOOTHING_STD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the death dataframe from (smoothed) raw data\n",
    "\n",
    "def smooth(x, gauss_std=10):\n",
    "    \"\"\"\n",
    "    gauss_std: standard deviation of the Gaussian smoothing window applied to the death data.\n",
    "    \"\"\"\n",
    "    if gauss_std <= 0:\n",
    "        return x\n",
    "    # To invalidate the near-edge results, bookend the input x with nans\n",
    "    x = np.concatenate([[np.nan], np.array(x), [np.nan]])\n",
    "    \n",
    "    kernel = scipy.stats.norm.pdf(\n",
    "        np.linspace(-3*gauss_std, 3*gauss_std, 1+6*gauss_std),\n",
    "        scale=gauss_std\n",
    "    )\n",
    "    normer = np.ones_like(x)\n",
    "    smoothed_x = convolve(x, kernel, mode='same') / convolve(normer, kernel, mode='same')\n",
    "    \n",
    "    # Remove the indices added by 